{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "484ebad5-4aeb-455e-9741-318d2c25afe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant packages\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "from librosa import display\n",
    "from PIL import Image\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "78c830d5-e51f-404a-91e3-2de060d20b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model. This model was built and trained in the 'Sound_Classifier_Models' notebook\n",
    "model = load_model('model/sound_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "187e0353-ef65-4ddc-a975-52e634055c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The model returns a numerical predicted class we'll use this mapping to return the corresponding label\n",
    "class_mapping = {0: 'Speech', 1: 'Animal', 2: 'Vehicle', 3: 'Music'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "386ee389-2801-4d5f-b7cc-41687d0fd37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function that classifies a random ten second clip from a single audio file\n",
    "def classify_sound(audio_file_path):\n",
    "    \n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(audio_file_path, sr=22050)\n",
    "    \n",
    "     # Randomly select a 10-second clip\n",
    "    clip_duration = 10  # in seconds\n",
    "    total_duration = librosa.get_duration(y=y, sr=sr)\n",
    "    if total_duration <= clip_duration:\n",
    "        start_time = 0.0\n",
    "    else:\n",
    "        start_time = random.uniform(0, total_duration - clip_duration)\n",
    "        \n",
    "    y_clip = y[int(start_time * sr):int((start_time + clip_duration) * sr)]\n",
    "    \n",
    "    # Compute the mel spectrogram\n",
    "    M = librosa.feature.melspectrogram(y=y_clip, sr=sr, n_mels=128, fmax=sr/2, n_fft=2048)\n",
    "    M_db = librosa.power_to_db(M, ref=np.max)\n",
    "\n",
    "    # Convert the mel spec to an image\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    librosa.display.specshow(M_db, cmap='inferno', x_axis='time', y_axis='mel')\n",
    "    plt.axis('off')\n",
    "\n",
    "    #capture image bytes and save in memory. This way user isn't saving a bunch of images on their machine.\n",
    "    img_bytes = io.BytesIO()\n",
    "    plt.savefig(img_bytes, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "    img_bytes.seek(0)\n",
    "\n",
    "    #open image from bytes and preprocess (convert to rgb, resize to inpute size, normal per RGB, add batch dimension)\n",
    "    img=Image.open(img_bytes)\n",
    "    spec_resized = img.convert('RGB').resize((128, 128))\n",
    "    spec_resized = np.array(spec_resized) / 255\n",
    "    spec_reshaped = spec_resized.reshape(1, *spec_resized.shape)\n",
    "\n",
    "    preds = model.predict(spec_reshaped)\n",
    "    pred_class = np.argmax(preds)\n",
    "    pred_label = class_mapping.get(pred_class, 'Unkown')\n",
    "\n",
    "    return pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "de7a1fac-2e31-4eca-a9b1-194d6406bc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through multiple audio files in a folder\n",
    "# Initialize a dictionary to store the count for each class\n",
    "def classify_folder(folder_path):\n",
    "    class_counts = {'Speech': 0, 'Animal': 0, 'Vehicle': 0, 'Music': 0}\n",
    "    results = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            audio_file_path = os.path.join(root, file)\n",
    "            if any(file.lower().endswith(ext) for ext in ['.wav', '.mp3', '.ogg', '.flac']):\n",
    "                pred_label = classify_sound(audio_file_path)\n",
    "                results.append((file, pred_label))\n",
    "                class_counts[pred_label] += 1\n",
    "\n",
    "    total_files = len(results)\n",
    "\n",
    "    st.header(\"Results:\")\n",
    "    st.markdown(\"### Class Distribution:\")\n",
    "    class_distribution_data = {\"Class\": [], \"Percentage\": []}\n",
    "    for class_label, count in class_counts.items():\n",
    "        percentage = (count / total_files) * 100\n",
    "        class_distribution_data[\"Class\"].append(class_label)\n",
    "        class_distribution_data[\"Percentage\"].append(f\"{percentage:.2f}%\")\n",
    "\n",
    "    st.table(class_distribution_data)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "718f9071-f7ff-4319-b6a9-deddee5c43d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    st.title(\"Sound Classification App\")\n",
    "    st.markdown(\"## What's making that sound?\")\n",
    "\n",
    "    # Allow user to input the folder path\n",
    "    folder_path = st.text_input(\"Enter the filepath where your audio files are saved:\")\n",
    "\n",
    "    if folder_path and os.path.exists(folder_path):\n",
    "        # Classify audio files in the specified folder\n",
    "        results = classify_folder(folder_path)\n",
    "\n",
    "        # Display results in a table\n",
    "        st.markdown(\"### Classification Results:\")\n",
    "        classification_results_data = {\"File\": [], \"Class\": []}\n",
    "        for audio_file, pred_label in results:\n",
    "            classification_results_data[\"File\"].append(audio_file)\n",
    "            classification_results_data[\"Class\"].append(pred_label)\n",
    "\n",
    "        st.table(classification_results_data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc350d11-967b-4227-b5c4-2ed355ce3b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn2",
   "language": "python",
   "name": "learn2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
